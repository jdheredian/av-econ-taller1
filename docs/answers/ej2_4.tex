\begin{tcolorbox}[breakable]

El estimador clusterizado es:
\[
\hat{\mathbb{V}}_{\text{CL}}[\hat\beta]
  = \frac{\displaystyle\sum_g \left(\sum_{i \in g} x_i\,\hat\varepsilon_i\right)^{\!2}}{\left(\sum_i x_i^2\right)^2}.
\]
Para cada cluster $g$, expandiendo el cuadrado:
\[
\left(\sum_{i \in g} x_i\,\hat\varepsilon_i\right)^{\!2}
  = \sum_{i \in g} x_i^2\,\hat\varepsilon_i^2
  \;+\; \sum_{\substack{i,j \in g \\ i \neq j}} x_i\,x_j\,\hat\varepsilon_i\,\hat\varepsilon_j.
\]
Sumando sobre todos los colegios $g$:
\[
\sum_g \left(\sum_{i \in g} x_i\,\hat\varepsilon_i\right)^{\!2}
  = \underbrace{\sum_i x_i^2\,\hat\varepsilon_i^2}_{\text{términos diagonales}}
  \;+\; \underbrace{\sum_g\sum_{\substack{i,j \in g \\ i \neq j}} x_i x_j\,\hat\varepsilon_i\,\hat\varepsilon_j}_{\text{productos cruzados intra-colegio}}.
\]
Dividiendo por $(\sum_i x_i^2)^2$ se obtiene:
\[
\hat{\mathbb{V}}_{\text{CL}}[\hat\beta]
  = \underbrace{\frac{\sum_i x_i^2\,\hat\varepsilon_i^2}{\left(\sum_i x_i^2\right)^2}}_{\displaystyle=\;\hat{\mathbb{V}}_{\text{HC}}[\hat\beta]}
  \;+\; \frac{\displaystyle\sum_g\sum_{\substack{i,j \in g \\ i \neq j}} x_i x_j\,\hat\varepsilon_i\,\hat\varepsilon_j}{\left(\sum_i x_i^2\right)^2}.
\tag{$\star$}
\]
El primer término es exactamente el estimador HC de White. El segundo captura los productos cruzados intra-colegio.


Por otro lado, ser robusto a heterocedasticidad significa que $\hat{\mathbb{V}}_{\text{CL}}$ converge en probabilidad a la varianza verdadera de $\hat\beta$ incluso cuando $\mathbb{V}[\varepsilon_i] = \sigma_i^2$ varía entre individuos.

La varianza verdadera del estimador MCO bajo heterocedasticidad sin correlación entre individuos es (Caso 2):
\[
\mathbb{V}[\hat\beta] = \frac{\sum_i x_i^2\,\sigma_i^2}{\left(\sum_i x_i^2\right)^2}.
\]
Tomamos el comportamiento asintótico de cada sumando:

Según White (1980), $\hat\varepsilon_i^2 \xrightarrow{p} \varepsilon_i^2$ ya que $\hat\varepsilon_i \xrightarrow{p} \varepsilon_i$ conforme $N\to\infty$. Como $\mathbb{E}[\varepsilon_i] = 0$, se tiene $\mathbb{E}[\varepsilon_i^2] = \mathbb{V}[\varepsilon_i] = \sigma_i^2$. Por tanto:
\[
\frac{\sum_i x_i^2\,\hat\varepsilon_i^2}{\left(\sum_i x_i^2\right)^2}
  \;\xrightarrow{p}\;
  \frac{\sum_i x_i^2\,\sigma_i^2}{\left(\sum_i x_i^2\right)^2}
  = \mathbb{V}[\hat\beta].
\]

Bajo solo heterocedasticidad (sin correlación intra-colegio), $\mathrm{Cov}(\varepsilon_i,\varepsilon_j) = 0$ para todo $i\neq j$, incluso si pertenecen al mismo colegio. Como $\mathbb{E}[\varepsilon_i]=0$, se tiene $\mathrm{Cov}(\varepsilon_i,\varepsilon_j)=\mathbb{E}[\varepsilon_i\varepsilon_j]$. Por tanto:
\[
\mathbb{E}\!\left[\sum_g\sum_{\substack{i,j\in g \\ i\neq j}} x_ix_j\,\hat\varepsilon_i\,\hat\varepsilon_j\right]
  \approx \sum_g\sum_{\substack{i,j\in g \\ i\neq j}} x_ix_j\,\underbrace{\mathbb{E}[\varepsilon_i\varepsilon_j]}_{=\,\mathrm{Cov}(\varepsilon_i,\varepsilon_j)=\,0}
  = 0.
\]
Combinando ambos resultados:
\[
\hat{\mathbb{V}}_{\text{CL}}[\hat\beta]
  \;\xrightarrow{p}\;
  \mathbb{V}[\hat\beta] + 0
  = \mathbb{V}[\hat\beta],
\]
lo que demuestra que $\hat{\mathbb{V}}_{\text{CL}}$ es consistente bajo heterocedasticidad.

\medskip

Si cada observación forma su propio cluster ($n_g = 1$ para todo $g$), no existen pares $i \neq j$ dentro de ningún cluster. Los términos cruzados desaparecen identicamente:
\[
\sum_g\sum_{\substack{i,j\in g \\ i\neq j}} x_ix_j\,\hat\varepsilon_i\hat\varepsilon_j = 0 \quad \text{(no hay pares intra-cluster)}.
\]
Por tanto:
\[
\hat{\mathbb{V}}_{\text{CL}}^{n_g=1}[\hat\beta]
  = \frac{\sum_i x_i^2\,\hat\varepsilon_i^2}{\left(\sum_i x_i^2\right)^2}
  = \hat{\mathbb{V}}_{\text{HC}}[\hat\beta].
\]
El estimador HC es el caso particular del clusterizado cuando el nivel de agrupación es el individuo. 

\medskip

La diferencia entre ambos estimadores es:
\[
\hat{\mathbb{V}}_{\text{CL}} - \hat{\mathbb{V}}_{\text{HC}}
  = \frac{\displaystyle\sum_g\sum_{\substack{i,j\in g \\ i\neq j}} x_ix_j\,\hat\varepsilon_i\hat\varepsilon_j}{\left(\sum_i x_i^2\right)^2}.
\]
Si la correlación intra-colegio es positiva ($\mathrm{Cov}(\varepsilon_i,\varepsilon_j) > 0$ para $i\neq j$ en el mismo colegio), los residuos de compañeros de colegio tienden a tener el mismo signo. El producto $\hat\varepsilon_i\hat\varepsilon_j > 0$ en promedio, y dado que $x_i, x_j > 0$, porque la variable de tratamiento es un indicador, los términos cruzados son positivos en promedio, haciendo $\hat{\mathbb{V}}_{\text{CL}} > \hat{\mathbb{V}}_{\text{HC}}$.

En este caso, los estudiantes del mismo colegio comparten entorno institucional, recursos pedagógicos, calidad del director y composición de pares. Estas características comunes generan factores no observados compartidos que se trasladan al término de error, induciendo correlación intra-colegio positiva. Ignorar lo anterior y usar solo $\hat{\mathbb{V}}_{\text{HC}}$ produce errores estándar artificialmente pequeños, estadísticos $t$ inflados e intervalos de confianza demasiado estrechos, lo que lleva a rechazar $H_0$ con mayor frecuencia que el nivel nominal.
\end{tcolorbox}
